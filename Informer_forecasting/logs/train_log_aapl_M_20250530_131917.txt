Args in experiment:
Namespace(model='informer', data='custom', root_path='./data/', data_path='AAPL_M.csv', features='M', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=24, enc_in=5, dec_in=5, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=4, itr=1, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des='aapl_M_test_aapl_M_20250530_131917', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='d')
Use GPU: cuda:0
>>>>>>>start training : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_aapl_M_test_aapl_M_20250530_131917_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 137
val 14
test 50
Epoch: 1 cost time: 0.3526294231414795
Epoch: 1, Steps: 8 | Train Loss: 8.2467224 Vali Loss: nan Test Loss: 2.2733934
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.12548542022705078
Epoch: 2, Steps: 8 | Train Loss: 0.9112939 Vali Loss: nan Test Loss: 4.7285690
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.10901546478271484
Epoch: 3, Steps: 8 | Train Loss: 0.6480551 Vali Loss: nan Test Loss: 6.7183309
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.12277984619140625
Epoch: 4, Steps: 8 | Train Loss: 0.5201846 Vali Loss: nan Test Loss: 4.9231744
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.15386676788330078
Epoch: 5, Steps: 8 | Train Loss: 0.4866743 Vali Loss: nan Test Loss: 5.2423019
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.11990070343017578
Epoch: 6, Steps: 8 | Train Loss: 0.4589232 Vali Loss: nan Test Loss: 5.6090951
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.11062765121459961
Epoch: 7, Steps: 8 | Train Loss: 0.4633123 Vali Loss: nan Test Loss: 5.5942001
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.10753870010375977
Epoch: 8, Steps: 8 | Train Loss: 0.4544208 Vali Loss: nan Test Loss: 5.5069394
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.12360405921936035
Epoch: 9, Steps: 8 | Train Loss: 0.4532592 Vali Loss: nan Test Loss: 5.5899415
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.11996054649353027
Epoch: 10, Steps: 8 | Train Loss: 0.4787458 Vali Loss: nan Test Loss: 5.5015907
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.953125e-06
>>>>>>>testing : informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_aapl_M_test_aapl_M_20250530_131917_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 50
test shape: (3, 16, 24, 1) (3, 16, 24, 5)
test shape: (48, 24, 1) (48, 24, 5)
mse:5.619420528411865, mae:2.0607378482818604
